{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data_loading import DlDataset\n",
    "from src.convnet import do_train_trials, train_net, evaluate_net_classes, NumNet, ModelPerformanceSummary\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not very elegant but removes all the warnings about deprecated upsample funtion\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for the boolean target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data for a 1000 pairs\n",
    "N = 1000\n",
    "dataset = DlDataset(N, normalize=True, upsample=None)\n",
    "datasetShape = list(dataset.__shape__()[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Model architectures **\n",
    "Number of trainable paramaters should be below 100'000\n",
    "1. 2 conv layers, 2 linear layers, no batch norm\n",
    "2. 2 conv layers, 2 batch norm layers, 2 linear layers\n",
    "3. 3 conv layers, 2 linear layers, no batch norm\n",
    "4. 2 conv layers, 2 batch norm layers, 2 linear layers, 1 dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The same net using NumNet class\n",
    "# Dropout layer\n",
    "# {'Type':'DropoutLayer', 'p':0.2}\n",
    "models = []\n",
    "\n",
    "# 2 convolutional layers followed by 2 linear layers\n",
    "config_2c_2l = [{'Type': 'ConvLayer', 'out_channels':8, 'activation':'ReLU()', 'kernel_size':5},\n",
    "          {'Type': 'ConvLayer', 'out_channels':16, 'activation':'ReLU()', 'kernel_size':3},\n",
    "          {'Type': 'LinearLayer', 'out_features':32, 'activation':'ReLU()'},\n",
    "          {'Type': 'LinearLayer', 'out_features':2}]\n",
    "models.append(NumNet(datasetShape, config_2c_2l, name='2conv_2lin'))\n",
    "\n",
    "# 2 convolutional layers followed by 2 linear layers with batch norm after each conv layer\n",
    "config_2c_2l_2bn = [{'Type': 'ConvLayer', 'out_channels':8, 'activation':'ReLU()', 'kernel_size':5},\n",
    "          {'Type': 'BatchNormLayer'},\n",
    "          {'Type': 'ConvLayer', 'out_channels':16, 'activation':'ReLU()', 'kernel_size':3},\n",
    "          {'Type': 'BatchNormLayer'},\n",
    "          {'Type': 'LinearLayer', 'out_features':32, 'activation':'ReLU()'},\n",
    "          {'Type': 'LinearLayer', 'out_features':2}]\n",
    "models.append(NumNet(datasetShape, config_2c_2l_2bn, name='2conv_2lin_bnorm'))\n",
    "\n",
    "# 3 convolutional layers followed by 2 linear layers\n",
    "config_3c_2l = [{'Type': 'ConvLayer', 'out_channels':4, 'activation':'ReLU()', 'kernel_size':5},\n",
    "          {'Type': 'ConvLayer', 'out_channels':8, 'activation':'ReLU()', 'kernel_size':3},\n",
    "          {'Type': 'ConvLayer', 'out_channels':16, 'activation':'ReLU()', 'kernel_size':3},\n",
    "          {'Type': 'LinearLayer', 'out_features':32, 'activation':'ReLU()'},\n",
    "          {'Type': 'LinearLayer', 'out_features':2}]\n",
    "models.append(NumNet(datasetShape, config_3c_2l, name='3conv_2lin'))\n",
    "\n",
    "# 2 convolutional layers with batch norm and 1 maxpool, followed by 2 linear layers \n",
    "config_2c_2l_2bn_1do = [{'Type': 'ConvLayer', 'out_channels':32, 'activation':'ReLU()', 'kernel_size':5},\n",
    "          {'Type': 'MaxPoolLayer', 'pooling':2, 'stride':2},\n",
    "          {'Type': 'BatchNormLayer'},\n",
    "          {'Type': 'DropoutLayer', 'p':0.5},\n",
    "          {'Type': 'ConvLayer', 'out_channels':64, 'activation':'ReLU()', 'kernel_size':3},\n",
    "          #{'Type': 'MaxPoolLayer', 'pooling':2, 'stride':2},\n",
    "          {'Type': 'BatchNormLayer'},\n",
    "          {'Type': 'LinearLayer', 'out_features':128, 'activation':'ReLU()'},\n",
    "          #{'Type': 'DropoutLayer', 'p':0.5},\n",
    "          {'Type': 'LinearLayer', 'out_features':2}]\n",
    "models.append(NumNet(datasetShape, config_2c_2l_2bn_1do, name='2conv_2lin_2bn_1do'))\n",
    "\n",
    "for model in models:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train parameter\n",
    "epochs = 15\n",
    "eta = 5e-2\n",
    "lambda_l2 = 1e-3\n",
    "gamma = 0.2\n",
    "depth = 4\n",
    "n_filters = 3\n",
    "batch_spec = {'batch_size':4, 'shuffle':True, 'num_workers':4}\n",
    "\n",
    "device = torch.device('cpu') #Hannes' gpu is not supported but has cuda cores... \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Prepare dataloaderÂ£\n",
    "dataloader = []\n",
    "for mode in ['train','test']:\n",
    "    if mode == 'train':\n",
    "        dataset.train()\n",
    "    elif mode == 'test':\n",
    "        dataset.test()\n",
    "    dataloader.append(dataset.return_dataloader(**batch_spec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A single training run using the 'train_net' function: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train each model with the same parameters\n",
    "perf_summary = []\n",
    "for model in models:\n",
    "    print(\"-\"*100)\n",
    "    print(\"Running model: {}\".format(model.name()))\n",
    "    print(\"-\"*100)\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=eta, momentum=gamma)\n",
    "    #optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    performance, model = train_net(model, device, optim, criterion, dataloader,\n",
    "                                    epochs=epochs, lambda_=1e-3, reg_type=None, \n",
    "                                    save=False)\n",
    "    perf_summary.append(ModelPerformanceSummary(model, performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "fig = plt.figure('History Plot', figsize=(18,7))\n",
    "fig.suptitle('Performance of Networks', fontsize=16)\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "for i,mod_perf in enumerate(perf_summary):\n",
    "    model_name = mod_perf.model\n",
    "    avg_loss_train = mod_perf.get_performance('train_loss')\n",
    "    avg_loss_test = mod_perf.get_performance('test_loss')\n",
    "    ax1.set_title('Error')\n",
    "    ax1.plot(range(0,epochs), avg_loss_train, linestyle='-', color=colors[i%8], label = model_name + ' train')\n",
    "    ax1.plot(range(0,epochs), avg_loss_test, linestyle='--', color=colors[i%8], label = model_name + ' valid.')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Cross Entropy Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for i,mod_perf in enumerate(perf_summary):\n",
    "    model_name = mod_perf.model\n",
    "    avg_acc_train = mod_perf.get_performance('train_accuracy')\n",
    "    avg_acc_test = mod_perf.get_performance('test_accuracy')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.plot(range(0,epochs), avg_acc_train, linestyle='-', color=colors[i%8], label = model_name + ' train')\n",
    "    ax2.plot(range(0,epochs), avg_acc_test, linestyle='--', color=colors[i%8], label = model_name + ' valid.')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy [% correct]')\n",
    "    print('Model: {:<20} max Test Acc: {:>5.3f}'.format(model_name, max(avg_acc_test)))\n",
    "ax2.grid()\n",
    "ax2.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.test()\n",
    "dataset.infere(models[3],5);\n",
    "dataset.infere(models[3],6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Multiple training trials using the 'do_train_trials' function: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_summaries = []\n",
    "for model in models:\n",
    "    print(\"-\"*100)\n",
    "    print(\"Running model: {}\".format(model.name()))\n",
    "    print(\"-\"*100)\n",
    "    optim_spec = {'type':'SGD', 'lr':eta, 'momentum':gamma}\n",
    "    batch_spec = {'batch_size': 100, 'shuffle':True, 'num_workers':4}\n",
    "    \n",
    "    performance = do_train_trials(5, model, device, optim_spec, criterion, dataset, batch_spec,\n",
    "                                    epochs=epochs, lambda_=1e-3, reg_type=None, \n",
    "                                    save=False)\n",
    "    trial_summaries.append(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_summaries = perf_summary[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_summaries[1].get_performance('std_train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure('History Plot', figsize=(18,7))\n",
    "fig.suptitle('Averaged Performance of Networks', fontsize=16)\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "for i,mod_perf in enumerate(trial_summaries):\n",
    "    model_name = mod_perf.model\n",
    "    avg_loss_train = mod_perf.get_performance('avg_train_loss')\n",
    "    avg_loss_test = mod_perf.get_performance('avg_test_loss')\n",
    "    std_loss_train = mod_perf.get_performance('std_train_loss')\n",
    "    std_loss_test = mod_perf.get_performance('std_test_loss')\n",
    "    ax1.set_title('Error') \n",
    "    ax1.errorbar(range(0,epochs), avg_loss_train.numpy(), std_loss_train.numpy(), capsize=3, linestyle='-', color=colors[i%8], label = model_name + ' train')\n",
    "    ax1.errorbar(range(0,epochs), avg_loss_test.numpy(), std_loss_test.numpy(), capsize=3, linestyle='--', color=colors[i%8], label = model_name + ' valid.')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Cross Entropy Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for i,mod_perf in enumerate(trial_summaries):\n",
    "    model_name = mod_perf.model\n",
    "    avg_acc_train = mod_perf.get_performance('avg_train_accuracy')\n",
    "    avg_acc_test = mod_perf.get_performance('avg_test_accuracy')\n",
    "    std_acc_train = mod_perf.get_performance('std_train_accuracy')\n",
    "    std_acc_test = mod_perf.get_performance('std_test_accuracy')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.errorbar(range(0,epochs), avg_acc_train.numpy(), std_acc_train.numpy(), capsize=3, linestyle='-', color=colors[i%8], label = model_name + ' train')\n",
    "    ax2.errorbar(range(0,epochs), avg_acc_test.numpy(), std_acc_test.numpy(), capsize=3, linestyle='--', color=colors[i%8], label = model_name + ' valid.')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy [% correct]')\n",
    "    print('Model: {:<20} max Test Acc: {:>5.3f}'.format(model_name, max(avg_acc_test)))\n",
    "ax2.grid()\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for the digit classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for classes and not the target.\n",
    "\n",
    "dataset_train_classes = DlDataset(N, normalize=True, upsample=None, split_dataset = True)\n",
    "\n",
    "dataset_test_classes = DlDataset(N, normalize=True, upsample=None, split_dataset = True)\n",
    "\n",
    "dataset_train_classes.train()\n",
    "dataset_test_classes.test()\n",
    "\n",
    "\n",
    "datasetShape_classes = list(dataset_train_classes.__shape__()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The same net using NumNet class\n",
    "# Dropout layer\n",
    "# {'Type':'DropoutLayer', 'p':0.2}\n",
    "models = []\n",
    "\n",
    "# 2 convolutional layers followed by 2 linear layers\n",
    "config_2c_2l = [{'Type': 'ConvLayer', 'out_channels':8, 'activation':'ReLU()', 'kernel_size':5},\n",
    "          {'Type': 'ConvLayer', 'out_channels':16, 'activation':'ReLU()', 'kernel_size':3},\n",
    "          {'Type': 'LinearLayer', 'out_features':32, 'activation':'ReLU()'},\n",
    "          {'Type': 'LinearLayer', 'out_features':10}]\n",
    "models.append(NumNet(datasetShape_classes, config_2c_2l, name='2conv_2lin'))\n",
    "\n",
    "# 2 convolutional layers followed by 2 linear layers with batch norm after each conv layer\n",
    "config_2c_2l_2bn = [{'Type': 'ConvLayer', 'out_channels':8, 'activation':'ReLU()', 'kernel_size':5},\n",
    "          {'Type': 'BatchNormLayer'},\n",
    "          {'Type': 'ConvLayer', 'out_channels':16, 'activation':'ReLU()', 'kernel_size':3},\n",
    "          {'Type': 'BatchNormLayer'},\n",
    "          {'Type': 'LinearLayer', 'out_features':32, 'activation':'ReLU()'},\n",
    "          {'Type': 'LinearLayer', 'out_features':10}]\n",
    "models.append(NumNet(datasetShape_classes, config_2c_2l_2bn, name='2conv_2lin_2bn'))\n",
    "\n",
    "# 3 convolutional layers followed by 2 linear layers\n",
    "config_3c_2l = [{'Type': 'ConvLayer', 'out_channels':4, 'activation':'ReLU()', 'kernel_size':5},\n",
    "          {'Type': 'ConvLayer', 'out_channels':8, 'activation':'ReLU()', 'kernel_size':3},\n",
    "          {'Type': 'ConvLayer', 'out_channels':16, 'activation':'ReLU()', 'kernel_size':3},\n",
    "          {'Type': 'LinearLayer', 'out_features':32, 'activation':'ReLU()'},\n",
    "          {'Type': 'LinearLayer', 'out_features':10}]\n",
    "models.append(NumNet(datasetShape_classes, config_3c_2l, name='3conv_2lin'))\n",
    "\n",
    "# 2 convolutional layers with batch norm and 1 maxpool, followed by 2 linear layers \n",
    "config_2c_2l_2bn_1do = [{'Type': 'ConvLayer', 'out_channels':32, 'activation':'ReLU()', 'kernel_size':5},\n",
    "          {'Type': 'MaxPoolLayer', 'pooling':2, 'stride':2},\n",
    "          {'Type': 'BatchNormLayer'},\n",
    "          {'Type': 'DropoutLayer', 'p':0.5},\n",
    "          {'Type': 'ConvLayer', 'out_channels':64, 'activation':'ReLU()', 'kernel_size':3},\n",
    "          #{'Type': 'MaxPoolLayer', 'pooling':2, 'stride':2},\n",
    "          {'Type': 'BatchNormLayer'},\n",
    "          {'Type': 'LinearLayer', 'out_features':128, 'activation':'ReLU()'},\n",
    "          #{'Type': 'DropoutLayer', 'p':0.5},\n",
    "          {'Type': 'LinearLayer', 'out_features':10}]\n",
    "models.append(NumNet(datasetShape_classes, config_2c_2l_2bn_1do, name='2conv_2lin_2bn_1do'))\n",
    "\n",
    "for model in models:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train parameter\n",
    "epochs = 30\n",
    "mini_batch_size = 100\n",
    "eta = 5e-2\n",
    "lambda_l2 = 1e-3\n",
    "gamma = 0.2\n",
    "depth = 4\n",
    "n_filters = 3\n",
    "\n",
    "device = torch.device('cpu') #Hannes' gpu is not supported but has cuda cores... \n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "dataloader = []\n",
    "dataloader.append(DataLoader(dataset_train_classes, batch_size=mini_batch_size,shuffle=True, num_workers=4))\n",
    "dataloader.append(DataLoader(dataset_test_classes, batch_size=mini_batch_size,shuffle=True, num_workers=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train each model with the same parameters\n",
    "perf_summary = []\n",
    "for model in models:\n",
    "    print(\"-\"*100)\n",
    "    print(\"Running model: {}\".format(model.name()))\n",
    "    print(\"-\"*100)\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=eta, momentum=gamma)\n",
    "    #optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    performance, model = train_net(model, device, optim, criterion, dataloader,\n",
    "                                    epochs=epochs, lambda_=1e-3, reg_type=None, \n",
    "                                    save=False)\n",
    "    perf_summary.append(ModelPerformanceSummary(model, performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "fig = plt.figure('History Plot', figsize=(18,7))\n",
    "fig.suptitle('Performance of Networks', fontsize=16)\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "for i,mod_perf in enumerate(perf_summary):\n",
    "    model_name = mod_perf.model.name()\n",
    "    avg_loss_train = mod_perf.get_performance('train_loss')\n",
    "    avg_loss_test = mod_perf.get_performance('test_loss')\n",
    "    ax1.set_title('Error')\n",
    "    ax1.plot(range(0,epochs), avg_loss_train, linestyle='-', color=colors[i%8], label = model_name + ' train')\n",
    "    ax1.plot(range(0,epochs), avg_loss_test, linestyle='--', color=colors[i%8], label = model_name + ' valid.')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Cross Entropy Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for i,mod_perf in enumerate(perf_summary):\n",
    "    model_name = mod_perf.model.name()\n",
    "    avg_acc_train = mod_perf.get_performance('train_accuracy')\n",
    "    avg_acc_test = mod_perf.get_performance('test_accuracy')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.plot(range(0,epochs), avg_acc_train, linestyle='-', color=colors[i%8], label = model_name + ' train')\n",
    "    ax2.plot(range(0,epochs), avg_acc_test, linestyle='--', color=colors[i%8], label = model_name + ' valid.')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy [% correct]')\n",
    "    print('Model: {:<20} max Test Acc: {:>5.3f}'.format(model_name, max(avg_acc_test)))\n",
    "ax2.grid()\n",
    "ax2.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating target boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_accuracy = []\n",
    "for model in models:\n",
    "    target_accuracy.append(evaluate_net_classes(model,dataset_test_classes))\n",
    "    print('Model: {:<20} Target Acc: {:>5.3f}'.format(model.name(), target_accuracy[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_classes.selectSplittedDataset('left')\n",
    "pred_1, classes_1, target_1 = dataset_test_classes.infere(models[3],10);\n",
    "\n",
    "dataset_test_classes.selectSplittedDataset('right')\n",
    "pred_2, classes_2, target_2 = dataset_test_classes.infere(models[3],10);\n",
    "print(\"Real Target is: {}\".format(target_1))\n",
    "print(\"Predicted Target is: {}\".format((pred_1 <= pred_2).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
