{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import src.modules as module\n",
    "from src.optimizer import SGD\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x249ea5a88d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_disc_set(nb):\n",
    "    input = torch.Tensor(nb, 2).uniform_(0, 1)\n",
    "    \n",
    "    target = abs(input.pow(2).sum(1).sub(1 / (2*math.pi)).sign().add(-1).div(2).long())\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "train_input, train_target = generate_disc_set(N)\n",
    "test_input, test_target = generate_disc_set(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing mse\n",
    "loss = module.LossMSE()\n",
    "inputs = torch.tensor([[ 3., 0., 0., 0. ]])\n",
    "targets = torch.tensor([[ 3., 0., 5., 0. ]])\n",
    "loss(inputs, targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu1\n",
      "tensor([[ 0.4640, -0.3979]])\n"
     ]
    }
   ],
   "source": [
    "#testing sequential, tanh, linear, relu\n",
    "model = module.Sequential(('lin1',module.Linear(4,3)),('relu1',module.ReLU()),('lin2',module.Linear(3,2)))\n",
    "optim = SGD(model.parameters(), lr=0.01)\n",
    "print(model[1].name)\n",
    "print(model(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target, model, optim, epochs):\n",
    "    for i in range(epochs):\n",
    "        print(\"Epoch {0}\".format(i))\n",
    "        out = model(inputs)\n",
    "        print(\"Out {0}\".format(out))\n",
    "        print(\"Loss {0}\".format(loss(out, target)))\n",
    "        optim.zero_grad()\n",
    "        d_loss = loss.backward(out, target)\n",
    "        model.backward(d_loss)\n",
    "        optim.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Out tensor([[ 0.4640, -0.3979]])\n",
      "Loss 0.23516052961349487\n",
      "Gradient wrt to input output of module lin2 tensor([[0.2734, 0.1686, 0.3170]])\n",
      "Gradient wrt to input output of module relu1 tensor([[0.2734, 0.0000, 0.3170]])\n",
      "Gradient wrt to input output of module lin1 tensor([[ 0.2826,  0.0536, -0.2738,  0.1234]])\n",
      "Epoch 1\n",
      "Out tensor([[ 0.4930, -0.3139]])\n",
      "Loss 0.17917945981025696\n",
      "Gradient wrt to input output of module lin2 tensor([[0.2072, 0.1482, 0.2419]])\n",
      "Gradient wrt to input output of module relu1 tensor([[0.2072, 0.0000, 0.2419]])\n",
      "Gradient wrt to input output of module lin1 tensor([[ 0.2110,  0.0407, -0.2083,  0.0936]])\n",
      "Epoch 2\n",
      "Out tensor([[ 0.5192, -0.2460]])\n",
      "Loss 0.13887010514736176\n",
      "Gradient wrt to input output of module lin2 tensor([[0.1584, 0.1312, 0.1864]])\n",
      "Gradient wrt to input output of module relu1 tensor([[0.1584, 0.0000, 0.1864]])\n",
      "Gradient wrt to input output of module lin1 tensor([[ 0.1597,  0.0311, -0.1600,  0.0716]])\n",
      "Epoch 3\n",
      "Out tensor([[ 0.5432, -0.1899]])\n",
      "Loss 0.10900871455669403\n",
      "Gradient wrt to input output of module lin2 tensor([[0.1218, 0.1168, 0.1447]])\n",
      "Gradient wrt to input output of module relu1 tensor([[0.1218, 0.0000, 0.1447]])\n",
      "Gradient wrt to input output of module lin1 tensor([[ 0.1220,  0.0240, -0.1236,  0.0551]])\n",
      "Epoch 4\n",
      "Out tensor([[ 0.5651, -0.1430]])\n",
      "Loss 0.08639734983444214\n",
      "Gradient wrt to input output of module lin2 tensor([[0.0939, 0.1044, 0.1128]])\n",
      "Gradient wrt to input output of module relu1 tensor([[0.0939, 0.0000, 0.1128]])\n",
      "Gradient wrt to input output of module lin1 tensor([[ 0.0939,  0.0186, -0.0959,  0.0426]])\n",
      "Epoch 5\n",
      "Out tensor([[ 0.5854, -0.1031]])\n",
      "Loss 0.0689815804362297\n",
      "Gradient wrt to input output of module lin2 tensor([[0.0725, 0.0935, 0.0881]])\n",
      "Gradient wrt to input output of module relu1 tensor([[0.0725, 0.0000, 0.0881]])\n",
      "Gradient wrt to input output of module lin1 tensor([[ 0.0725,  0.0144, -0.0746,  0.0329]])\n",
      "Epoch 6\n",
      "Out tensor([[ 0.6040, -0.0690]])\n",
      "Loss 0.05538776516914368\n",
      "Gradient wrt to input output of module lin2 tensor([[0.0560, 0.0840, 0.0689]])\n",
      "Gradient wrt to input output of module relu1 tensor([[0.0560, 0.0000, 0.0689]])\n",
      "Gradient wrt to input output of module lin1 tensor([[ 0.0561,  0.0111, -0.0580,  0.0255]])\n",
      "Epoch 7\n",
      "Out tensor([[ 0.6211, -0.0394]])\n",
      "Loss 0.04466589167714119\n",
      "Gradient wrt to input output of module lin2 tensor([[0.0431, 0.0756, 0.0539]])\n",
      "Gradient wrt to input output of module relu1 tensor([[0.0431, 0.0000, 0.0539]])\n",
      "Gradient wrt to input output of module lin1 tensor([[ 0.0434,  0.0086, -0.0451,  0.0197]])\n",
      "Epoch 8\n",
      "Out tensor([[ 0.6369, -0.0137]])\n",
      "Loss 0.036139748990535736\n",
      "Gradient wrt to input output of module lin2 tensor([[0.0331, 0.0681, 0.0421]])\n",
      "Gradient wrt to input output of module relu1 tensor([[0.0331, 0.0000, 0.0421]])\n",
      "Gradient wrt to input output of module lin1 tensor([[ 0.0335,  0.0066, -0.0350,  0.0151]])\n",
      "Epoch 9\n",
      "Out tensor([[0.6514, 0.0088]])\n",
      "Loss 0.029316112399101257\n",
      "Gradient wrt to input output of module lin2 tensor([[0.0253, 0.0614, 0.0327]])\n",
      "Gradient wrt to input output of module relu1 tensor([[0.0253, 0.0000, 0.0327]])\n",
      "Gradient wrt to input output of module lin1 tensor([[ 0.0258,  0.0051, -0.0270,  0.0116]])\n"
     ]
    }
   ],
   "source": [
    "train(inputs, torch.Tensor([[0.8,0.2]]), model, optim, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
